{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "iven the same dataset,\n",
    "\n",
    "- extract the most syntactically weighted N-grams, omitting nonsense (‘казалось бы’, ‘возможно предположить’, etc). The main idea is to extract the most valuable data from the text.\n",
    "\n",
    "- Try different models for a topic extraction. Which one performs better? What metrics were used to evaluate the model?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "from string import punctuation\n",
    "import gensim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lenta_data = pd.read_csv('E:/PycharmProjects/data/lenta-ru-news.csv')\n",
    "lenta_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean and preprocessing text data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.extend(['BBC', 'ВВС', 'РИА', 'Риа','риа', 'пресс центра', 'агенства','прайм тасс', 'ТАСС', \n",
    "                          'Интерфакс', 'Интерфакса', 'новости','пресс службы', 'интерфакс', 'интерфакса', 'мнен', 'дан'\n",
    "                          'Таким образом', 'как', 'по', 'в', 'результате', 'В', 'В результате', 'мнению', 'данным',\n",
    "                          'таким образом', 'согласно которым', 'до сих пор', 'понедельник', 'вторник', 'рбк', 'РБК', \n",
    "                          'итартасс', 'ссыл', 'ссылается', 'день', 'ночь', 'утро', 'вечер', 'Reuters',\n",
    "                          'наст', 'врем', 'ссылк', 'сообщ', 'агенств', 'сих', 'пор',\n",
    "                          'среда', 'четверг', 'пятница', 'суббота', 'воскресенье', 'лет', 'год', 'некотор', 'необход', \n",
    "                          'лиш', \"владимир\",'Associated Press',\n",
    "                          'сказ', 'больш', \"ЕЭС России\", 'eэс', 'Associated', 'соответств', 'говор', 'лучш', 'сообща',\n",
    "                          'новост', 'эх'\n",
    "                         ])\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "stemmer = SnowballStemmer(\"russian\") \n",
    "\n",
    "def preprocessing(text):\n",
    "    text = regex.sub('', text)\n",
    "    text = [token for token in text.split() if token not in russian_stopwords]\n",
    "    text = [stemmer.stem(token) for token in text] \n",
    "    text = [token for token in text if token not in russian_stopwords]\n",
    "    text = [token for token in text if token] \n",
    "    return ' '.join(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only 100 000 values from dataset, bcs original dataset is very big and process it take a lot of time:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lenta_data['text'][:100000] = lenta_data['text'][:100000].apply(lambda x: preprocessing(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing_data = pd.DataFrame({'text': lenta_data['text'][:100000]})\n",
    "preprocessing_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the bigrams and trigrams, using gensim:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = []\n",
    "for index, row in preprocessing_data.iterrows():\n",
    "        text.append(row['text'].split())\n",
    "\n",
    "from gensim.models import Phrases\n",
    "bigram = Phrases(text) \n",
    "trigram = Phrases(bigram[text])\n",
    "\n",
    "for idx in range(len(text)):\n",
    "    for token in bigram[text[idx]]:\n",
    "        if '_' in token:\n",
    "            text[idx].append(token)\n",
    "    for token in trigram[text[idx]]:\n",
    "        if '_' in token:\n",
    "            text[idx].append(token)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the bigrams, using nltk:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "texts = []\n",
    "for index, row in preprocessing_data.iterrows():\n",
    "        texts.append(row['text'].split())\n",
    "        \n",
    "from nltk.util import ngrams\n",
    "import  collections\n",
    "\n",
    "bigrams = [ngrams(text, 2) for text in texts]\n",
    "bigram_freq = [collections.Counter(bigram) for bigram in bigrams]\n",
    "# look at the most popular bigrams in the third and fourth text\n",
    "bigram_freq[2].most_common(5), bigram_freq[3].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create LDA-model for 100 000 items. \n",
    "\n",
    "A more detailed research will be carried out for 10 000 elements, bcs for 100 000 elements it`s take a lot of time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "\n",
    "dictionary = Dictionary(text)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.1)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in text]\n",
    "print('Количество уникальных токенов: %d' % len(dictionary))\n",
    "print('Количество документов: %d' % len(corpus))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "model = LdaMulticore(corpus = corpus, id2word = dictionary, num_topics = 22)\n",
    "model.show_topics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(model, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def calc_coherence_values(dictionary, corpus, texts, limit, start = 2, step = 2):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMulticore(corpus=corpus,id2word = dictionary, num_topics = num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model = model, texts = texts, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "model_list, coherence_values = calc_coherence_values(dictionary = dictionary, corpus=corpus, texts=text, start = 2, limit = 41, step = 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to define the optimal numbers of topics:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "limit, start, step = 41, 2, 3\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best coherence - for ~22 topics.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lsamodel = LsiModel(corpus, num_topics = 22, id2word = dictionary) \n",
    "lsamodel.print_topics(num_topics = 22, num_words = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_coherence_values_Lsi(dictionary, corpus, texts, limit, start = 2, step = 2):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LsiModel(corpus=corpus, id2word = dictionary, num_topics = num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model = model, texts = texts, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "model_list, coherence_values_Lsi = calc_coherence_values(dictionary = dictionary, corpus=corpus, texts=text, start = 2, limit = 41, step =3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "limit, start, step = 41, 2, 3\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values_Lsi)\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best coherence - for ~22 topics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Which one performs better? What metrics were used to evaluate the model?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LSA performs a little better, bcs its coherence score bigger (about 0.53) then LDA score (about 0.52), but there is no significant difference, and we can say that the models are about the same, bcs they give almost the same quality assessment results for the same number of topics.\n",
    "\n",
    "Coherence is a metric used to evaluate the quality of a model, based on 'c_v' measure."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coherence_values_Lsi, coherence_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save models for 100 000 items:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('model_lda.gensim')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lsamodel.save(\"model_lsa.gensim\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create and explore models for 10 000 items:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_preprocessing_data = pd.DataFrame({'text': preprocessing_data['text'][:10000]})\n",
    "new_preprocessing_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create N-grams:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = []\n",
    "for index, row in new_preprocessing_data.iterrows():\n",
    "        text.append(row['text'].split())\n",
    "\n",
    "from gensim.models import Phrases\n",
    "bigram = Phrases(text) \n",
    "trigram = Phrases(bigram[text])\n",
    "\n",
    "for idx in range(len(text)):\n",
    "    for token in bigram[text[idx]]:\n",
    "        if '_' in token:\n",
    "            text[idx].append(token)\n",
    "    for token in trigram[text[idx]]:\n",
    "        if '_' in token:\n",
    "            text[idx].append(token)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create LDA-model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "\n",
    "dictionary = Dictionary(text)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.1)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in text]\n",
    "print('Количество уникальных токенов: %d' % len(dictionary))\n",
    "print('Количество документов: %d' % len(corpus))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explore influence of hyperparameters on model quality. First, find optimal number of topics:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "def calc_coherence_values_new_LDA(dictionary, corpus, texts, limit, start = 2, step = 2):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMulticore(corpus=corpus,id2word = dictionary, num_topics = num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model = model, texts = texts, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "model_list, coherence_values = calc_coherence_values(dictionary = dictionary, corpus=corpus, texts=text, start = 2, limit = 20, step = 2)\n",
    "coherence_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimal number of topics is 6. Next, change hyperparameter eta and see result:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_coherence_values_hp(dictionary, corpus, texts, num_topics = 6, eta = [1, 0.01, 0.001, 0.0001, 0.00001]):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for eta_value in eta:\n",
    "        model = LdaMulticore(corpus=corpus,id2word = dictionary, num_topics = num_topics, eta = eta_value)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model = model, texts = texts, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "model_list, coherence_values_eta = calc_coherence_values_hp(dictionary = dictionary, corpus=corpus, texts=text)\n",
    "coherence_values_eta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that LDA-model quality get better if eta = 0.001. The worth res is got if eta = 0.00001.\n",
    "\n",
    "Next, let`s see how hp alpha influenced on the LDA-model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_coherence_values_hp_alpha(dictionary, corpus, texts, num_topics = 6, eta = 0.001):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for alpha_value in np.arange(1, 2, 0.1):\n",
    "        model = LdaMulticore(corpus=corpus,id2word = dictionary, num_topics = num_topics, alpha = alpha_value, eta = eta)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model = model, texts = texts, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "model_list, coherence_values_alpha = calc_coherence_values_hp_alpha(dictionary = dictionary, corpus=corpus, texts=text)\n",
    "coherence_values_alpha"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the results got worse. Also researched for alpha=[0, 1], but the result was just as bad."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the best LDA model create pyLDAvis display:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LdaMulticore(corpus=corpus,id2word = dictionary, num_topics = 6, eta = 0.001)\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(model, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At the pic we can see bubles approximately the same size, it means that topics are distributed about the same.\n",
    "Also, topics are scattered throughout the diagram and have virtually no overlap, it means that LDA topic model is good.\n",
    "\n",
    "Picture:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![LDA_for_10%20000.png](attachment:LDA_for_10%20000.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create LSI-vodel for 10 000 items:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lsamodel = LsiModel(corpus, num_topics = 6, id2word = dictionary) \n",
    "lsamodel.print_topics(num_topics = 6, num_words = 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_coherence_values_new_Lsi(dictionary, corpus, texts, limit, start = 2, step = 2):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LsiModel(corpus=corpus, id2word = dictionary, num_topics = num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model = model, texts = texts, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "model_list, coherence_values_Lsi = calc_coherence_values(dictionary = dictionary, corpus=corpus, texts=text, start = 2, limit = 20, step = 2)\n",
    "coherence_values_Lsi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "limit, start, step = 20, 2, 2\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values_Lsi)\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With hyperparameter tuning, the LDA model performed better than the LSA model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}